{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kDFgyaGD2KS",
        "outputId": "3d9e18b1-f281-44f1-92eb-c5c0ddcf0600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "!unzip -q \"/content/gdrive/My Drive/hw5.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/gdrive/My Drive/hw5_code.zip\""
      ],
      "metadata": {
        "id": "j6pxZwx9FXL2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You may want to install \"gprof2dot\"\n",
        "import io\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import sklearn.model_selection\n",
        "import sklearn.tree\n",
        "from numpy import genfromtxt\n",
        "from scipy import stats\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import pydot\n",
        "import random\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "eps = 1e-5  # a small number\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=3, feature_labels=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.features = feature_labels\n",
        "        self.left, self.right = None, None  # for non-leaf nodes\n",
        "        self.split_idx, self.thresh = None, None  # for non-leaf nodes\n",
        "        self.data, self.pred = None, None  # for leaf nodes\n",
        "\n",
        "    @staticmethod\n",
        "    def information_gain(X, y, thresh):\n",
        "        # TODO: implement information gain function\n",
        "        #here we make a helper function in order to properly conduct\n",
        "        #the information gain function\n",
        "        def helper(y):\n",
        "            totfeats = len(y)\n",
        "            feat_unique = np.unique(y, return_counts=True)\n",
        "            tot = 0\n",
        "            for feat in feat_unique[1]:\n",
        "                freq = feat/totfeats\n",
        "                #formulaically w subtract the xlog(x) value for the feat freqs\n",
        "                tot -= freq * np.log2(freq)\n",
        "            return tot\n",
        "        arrelt = np.where(X < thresh)[0]\n",
        "        eltofy = y[arrelt]\n",
        "        invarrelt = np.where(X >= thresh)[0]\n",
        "        eltofy2 = y[invarrelt]\n",
        "        lessinfo = helper(eltofy)\n",
        "        greaterinfo = helper(eltofy2)\n",
        "        #here we get all the values and just use our formula to get the info\n",
        "        a = (len(eltofy) * lessinfo + len(eltofy2) * greaterinfo)\n",
        "        b = (len(eltofy) + len(eltofy2))\n",
        "        return -1 * a / b\n",
        "\n",
        "    @staticmethod\n",
        "    def gini_impurity(X, y, thresh):\n",
        "        # TODO: implement gini impurity function\n",
        "        pass\n",
        "        #we can do this problem without actually implementing the gini impurity function\n",
        "\n",
        "    def split(self, X, y, idx, thresh):\n",
        "        X0, idx0, X1, idx1 = self.split_test(X, idx=idx, thresh=thresh)\n",
        "        y0, y1 = y[idx0], y[idx1]\n",
        "        return X0, y0, X1, y1\n",
        "\n",
        "    def split_test(self, X, idx, thresh):\n",
        "        idx0 = np.where(X[:, idx] < thresh)[0]\n",
        "        idx1 = np.where(X[:, idx] >= thresh)[0]\n",
        "        X0, X1 = X[idx0, :], X[idx1, :]\n",
        "        return X0, idx0, X1, idx1\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if self.max_depth > 0:\n",
        "            # compute entropy gain for all single-dimension splits,\n",
        "            # thresholding with a linear interpolation of 10 values\n",
        "            gains = []\n",
        "            # The following logic prevents thresholding on exactly the minimum\n",
        "            # or maximum values, which may not lead to any meaningful node\n",
        "            # splits.\n",
        "            thresh = np.array([\n",
        "                np.linspace(np.min(X[:, i]) + eps, np.max(X[:, i]) - eps, num=10)\n",
        "                for i in range(X.shape[1])\n",
        "            ])\n",
        "            for i in range(X.shape[1]):\n",
        "                gains.append([self.information_gain(X[:, i], y, t) for t in thresh[i, :]])\n",
        "\n",
        "            gains = np.nan_to_num(np.array(gains))\n",
        "            self.split_idx, thresh_idx = np.unravel_index(np.argmax(gains), gains.shape)\n",
        "            self.thresh = thresh[self.split_idx, thresh_idx]\n",
        "            X0, y0, X1, y1 = self.split(X, y, idx=self.split_idx, thresh=self.thresh)\n",
        "            if X0.size > 0 and X1.size > 0:\n",
        "                self.left = DecisionTree(\n",
        "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
        "                self.left.fit(X0, y0)\n",
        "                self.right = DecisionTree(\n",
        "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
        "                self.right.fit(X1, y1)\n",
        "            else:\n",
        "                self.max_depth = 0\n",
        "                self.data, self.labels = X, y\n",
        "                self.pred = stats.mode(y).mode[0]\n",
        "        else:\n",
        "            self.data, self.labels = X, y\n",
        "            self.pred = stats.mode(y).mode[0]\n",
        "        return self\n",
        "\n",
        "    #here we define a new fit function which we will explicitly using instead of\n",
        "    #the prior fit function\n",
        "    def baggedfit(self, X, y, r):\n",
        "        if self.max_depth > 0:\n",
        "            # compute entropy gain for all single-dimension splits,\n",
        "            # thresholding with a linear interpolation of 10 values\n",
        "            gains = []\n",
        "            # The following logic prevents thresholding on exactly the minimum\n",
        "            # or maximum values, which may not lead to any meaningful node\n",
        "            # splits.\n",
        "\n",
        "            #here we want to define our space set for the X data set and then we\n",
        "            #want to get the random vals to effectively generate this random fit\n",
        "            #this will help us create an accurate function and if our value isnt\n",
        "            #in our rfv then we will append -100s to the gains similar the the \n",
        "            #method discussed earlier\n",
        "            rows = np.arange(X.shape[1])\n",
        "            randforestvals = np.random.choice(rows, r, replace = False)\n",
        "            thresh = np.array([\n",
        "                np.linspace(np.min(X[:, i]) + eps, np.max(X[:, i]) - eps, num=10)\n",
        "                for i in range(X.shape[1])\n",
        "            ])\n",
        "            for i in range(X.shape[1]):\n",
        "                if i in randforestvals:\n",
        "                    gains.append([self.information_gain(X[:, i], y, t) for t in thresh[i, :]])\n",
        "                else:\n",
        "                    gains.append([-100 for t in thresh[i, :]])\n",
        "\n",
        "            gains = np.nan_to_num(np.array(gains))\n",
        "            self.split_idx, thresh_idx = np.unravel_index(np.argmax(gains), gains.shape)\n",
        "            self.thresh = thresh[self.split_idx, thresh_idx]\n",
        "            X0, y0, X1, y1 = self.split(X, y, idx=self.split_idx, thresh=self.thresh)\n",
        "            if X0.size > 0 and X1.size > 0:\n",
        "              #here we also want to use baggedfit instead of our regular fit to \n",
        "              #continue our pattern\n",
        "                self.left = DecisionTree(\n",
        "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
        "                self.left.baggedfit(X0, y0, r)\n",
        "                self.right = DecisionTree(\n",
        "                    max_depth=self.max_depth - 1, feature_labels=self.features)\n",
        "                self.right.baggedfit(X1, y1, r)\n",
        "            else:\n",
        "                self.max_depth = 0\n",
        "                self.data, self.labels = X, y\n",
        "                self.pred = stats.mode(y).mode[0]\n",
        "        else:\n",
        "            self.data, self.labels = X, y\n",
        "            self.pred = stats.mode(y).mode[0]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.max_depth == 0:\n",
        "            return self.pred * np.ones(X.shape[0])\n",
        "        else:\n",
        "            X0, idx0, X1, idx1 = self.split_test(X, idx=self.split_idx, thresh=self.thresh)\n",
        "            yhat = np.zeros(X.shape[0])\n",
        "            yhat[idx0] = self.left.predict(X0)\n",
        "            yhat[idx1] = self.right.predict(X1)\n",
        "            return yhat\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.max_depth == 0:\n",
        "            return \"%s (%s)\" % (self.pred, self.labels.size)\n",
        "        else:\n",
        "            return \"[%s < %s: %s | %s]\" % (self.features[self.split_idx],\n",
        "                                           self.thresh, self.left.__repr__(),\n",
        "                                           self.right.__repr__())\n",
        "    #here we define a function so that we can help display our nodes for \n",
        "    #the proper visualization:\n",
        "    def node_display(self, dat, c):\n",
        "      if not self.pred is None:\n",
        "        #our base case is when we finally have a prediction for the class\n",
        "        #of our data then we say it such as spam or ham\n",
        "        msg = c[self.pred[0]]\n",
        "        print(\"Therefore this email was \" + msg + \".\")\n",
        "      else:\n",
        "        #if we dont have the message yet we are displaying the nodes\n",
        "        msg=\"('\"\n",
        "        msg += self.features[self.split_idx]\n",
        "        val = dat[self.split_idx]\n",
        "        if (val < self.thresh):\n",
        "          #if we are below the threshold then we use this to \n",
        "          #properly print out our message for our feature\n",
        "          msg += \"') < \"\n",
        "          msg += str(self.thresh)\n",
        "          print(msg)\n",
        "          #here we print then move further down in the display function\n",
        "          self.left.node_display(dat, c)\n",
        "        else: \n",
        "          #this is the case for greater than or equal to thresh\n",
        "          msg += \"') >= \"\n",
        "          msg += str(self.thresh)\n",
        "          print(msg)\n",
        "          self.right.node_display(dat, c)\n",
        "\n",
        "\n",
        "#here before we had a bagged trees class and a separate randomforest class\n",
        "#but I found it easier to directly implement a randomforest instead of making\n",
        "#both, so I made a direct Randomforest class with all the appropriate parameters:   \n",
        "class RandomForest():\n",
        "    def __init__(self, d, feats, npr, fpr, n = 200):\n",
        "        self.n = n\n",
        "        self.max_depth = d\n",
        "        self.feature_labels = feats\n",
        "        #we are going to mak ea forest made up of a bunch of decision trees that\n",
        "        #we define earlier as follows:\n",
        "        self.btrees = [DecisionTree(self.max_depth, self.feature_labels) for i in range(self.n)]\n",
        "        \"\"\"self.decision_trees = [\n",
        "            sklearn.tree.DecisionTreeClassifier(random_state=i, **self.params)\n",
        "            for i in range(self.n)\n",
        "        ]\"\"\"\n",
        "        self.npr = npr\n",
        "        self.fpr = fpr\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        #here we create our fit function, and we use X.shape[0], so the total\n",
        "        #number of elts such as around 4200 is our space and we will iterate \n",
        "        #and get random subsamples and fit on each one for each of our trees\n",
        "        elts = np.arange(X.shape[0])\n",
        "        for b in self.btrees:\n",
        "          #we use our npr value in order to help randomize our choices\n",
        "            ss = np.random.choice(elts, self.npr, replace = True)\n",
        "            xs = X[ss]\n",
        "            ys = y[ss]\n",
        "            #we finally fit using our fpr value for m param\n",
        "            b.baggedfit(xs, ys, self.fpr)\n",
        "        return\n",
        "  \n",
        "    def predict(self, X):\n",
        "        #we want to create our fit function as follows, by starting our pred\n",
        "        #off as the np arr of ones for all the values then we iterate through\n",
        "        #each of our trees and we will predict our vals and add that to a \n",
        "        #stack horizontally and finally we want to append everything to get the\n",
        "        #real results\n",
        "        curr_p = -np.ones((X.shape[0], 1))\n",
        "        for b in self.btrees:\n",
        "            tree_pred = b.predict(X).reshape(X.shape[0], 1)\n",
        "            curr_p = np.hstack((curr_p, tree_pred))\n",
        "        allpreds = []\n",
        "        for elt in range(X.shape[0]):\n",
        "          #here we append with our tree preds\n",
        "            allpreds.append(stats.mode(curr_p[elt])[0][0])\n",
        "            #finally we want to return this all prediction as a array of ints\n",
        "            #for a proper prediction:\n",
        "        return np.array(allpreds).astype(int)\n",
        "\n",
        "#our old implementation which i just renamed and practically removed\n",
        "class aRandomForest():\n",
        "    def __init__(self, params=None, n=200, m=1):\n",
        "        if params is None:\n",
        "            params = {}\n",
        "        # TODO: implement function\n",
        "        pass\n",
        "\n",
        "\n",
        "def preprocess(data, fill_mode=True, min_freq=10, onehot_cols=[]):\n",
        "    # fill_mode = False\n",
        "\n",
        "    # Temporarily assign -1 to missing data\n",
        "    data[data == ''] = '-1'\n",
        "\n",
        "    # Hash the columns (used for handling strings)\n",
        "    onehot_encoding = []\n",
        "    onehot_features = []\n",
        "    for col in onehot_cols:\n",
        "        counter = Counter(data[:, col])\n",
        "        for term in counter.most_common():\n",
        "            if term[0] == '-1':\n",
        "                continue\n",
        "            if term[-1] <= min_freq:\n",
        "                break\n",
        "            onehot_features.append(term[0])\n",
        "            onehot_encoding.append((data[:, col] == term[0]).astype(float))\n",
        "        data[:, col] = '0'\n",
        "    onehot_encoding = np.array(onehot_encoding).T\n",
        "    data = np.hstack([np.array(data, dtype=float), np.array(onehot_encoding)])\n",
        "\n",
        "    # Replace missing data with the mode value. We use the mode instead of\n",
        "    # the mean or median because this makes more sense for categorical\n",
        "    # features such as gender or cabin type, which are not ordered.\n",
        "    if fill_mode:\n",
        "        for i in range(data.shape[-1]):\n",
        "            mode = stats.mode(data[((data[:, i] < -1 - eps) +\n",
        "                                    (data[:, i] > -1 + eps))][:, i]).mode[0]\n",
        "            data[(data[:, i] > -1 - eps) * (data[:, i] < -1 + eps)][:, i] = mode\n",
        "\n",
        "    return data, onehot_features\n",
        "\n",
        "\n",
        "def evaluate(clf):\n",
        "    print(\"Cross validation\", sklearn.model_selection.cross_val_score(clf, X, y))\n",
        "    if hasattr(clf, \"decision_trees\"):\n",
        "        counter = Counter([t.tree_.feature[0] for t in clf.decision_trees])\n",
        "        first_splits = [(features[term[0]], term[1]) for term in counter.most_common()]\n",
        "        print(\"First splits\", first_splits)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = \"titanic\"\n",
        "    params = {\n",
        "        \"max_depth\": 5,\n",
        "        # \"random_state\": 6,\n",
        "        \"min_samples_leaf\": 10,\n",
        "    }\n",
        "    N = 100\n",
        "\n",
        "    if dataset == \"titanic\":\n",
        "        # Load titanic data\n",
        "        path_train = 'hw5_code/dataset/titanic/titanic_training.csv'\n",
        "        data = genfromtxt(path_train, delimiter=',', dtype=None, encoding=None)\n",
        "        path_test = 'hw5_code/dataset/titanic/titanic_test_data.csv'\n",
        "        test_data = genfromtxt(path_test, delimiter=',', dtype=None, encoding=None)\n",
        "        y = data[1:, -1]  # label = survived\n",
        "        class_names = [\"Died\", \"Survived\"]\n",
        "        labeled_idx = np.where(y != '')[0]\n",
        "\n",
        "        y = np.array(y[labeled_idx])\n",
        "        y = y.astype(float).astype(int)\n",
        "\n",
        "\n",
        "        print(\"\\n\\nPart (b): preprocessing the titanic dataset\")\n",
        "        X, onehot_features = preprocess(data[1:, :-1], onehot_cols=[1, 5, 7, 8])\n",
        "        X = X[labeled_idx, :]\n",
        "        Z, _ = preprocess(test_data[1:, :], onehot_cols=[1, 5, 7, 8])\n",
        "        assert X.shape[1] == Z.shape[1]\n",
        "        features = list(data[0, :-1]) + onehot_features\n",
        "\n",
        "    elif dataset == \"spam\":\n",
        "        features = [\n",
        "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\", \"creative\",\n",
        "            \"height\", \"featured\", \"differ\", \"width\", \"other\", \"energy\", \"business\", \"message\",\n",
        "            \"volumes\", \"revision\", \"path\", \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
        "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\", \"square_bracket\",\n",
        "            \"ampersand\"\n",
        "        ]\n",
        "        assert len(features) == 32\n",
        "\n",
        "        # Load spam data\n",
        "        path_train = './dataset/spam/spam_data.mat'\n",
        "        data = scipy.io.loadmat(path_train)\n",
        "        X = data['training_data']\n",
        "        y = np.squeeze(data['training_labels'])\n",
        "        Z = data['test_data']\n",
        "        class_names = [\"Ham\", \"Spam\"]\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
        "\n",
        "    print(\"Features:\", features)\n",
        "    print(\"Train/test size:\", X.shape, Z.shape)\n",
        "\n",
        "    print(\"\\n\\nPart 0: constant classifier\")\n",
        "    print(\"Accuracy\", 1 - np.sum(y) / y.size)\n",
        "\n",
        "    # Basic decision tree\n",
        "    print(\"\\n\\nPart (a-b): simplified decision tree\")\n",
        "    dt = DecisionTree(max_depth=3, feature_labels=features)\n",
        "    dt.fit(X, y)\n",
        "    print(\"Predictions\", dt.predict(Z)[:100])\n",
        "\n",
        "    print(\"\\n\\nPart (c): sklearn's decision tree\")\n",
        "    clf = sklearn.tree.DecisionTreeClassifier(random_state=0, **params)\n",
        "    clf.fit(X, y)\n",
        "    evaluate(clf)\n",
        "    out = io.StringIO()\n",
        "\n",
        "    # You may want to install \"gprof2dot\"\n",
        "    sklearn.tree.export_graphviz(\n",
        "        clf, out_file=out, feature_names=features, class_names=class_names)\n",
        "    graph = pydot.graph_from_dot_data(out.getvalue())\n",
        "    pydot.graph_from_dot_data(out.getvalue())[0].write_pdf(\"%s-tree.pdf\" % dataset)\n",
        "\n",
        "    # TODO: implement and evaluate!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_T7WxpXEOQ2",
        "outputId": "5ab2dfc1-ff7a-4261-e168-cb2c56bbb398"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Part (b): preprocessing the titanic dataset\n",
            "Features: ['pclass', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked', 'male', 'female', 'S', 'C', 'Q']\n",
            "Train/test size: (999, 14) (310, 14)\n",
            "\n",
            "\n",
            "Part 0: constant classifier\n",
            "Accuracy 0.6166166166166166\n",
            "\n",
            "\n",
            "Part (a-b): simplified decision tree\n",
            "Predictions [1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0.]\n",
            "\n",
            "\n",
            "Part (c): sklearn's decision tree\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:283: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode = stats.mode(data[((data[:, i] < -1 - eps) +\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation [0.795      0.825      0.805      0.755      0.74371859]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn as sk\n",
        "features = [\n",
        "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\", \"creative\",\n",
        "            \"height\", \"featured\", \"differ\", \"width\", \"other\", \"energy\", \"business\", \"message\",\n",
        "            \"volumes\", \"revision\", \"path\", \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
        "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\", \"square_bracket\",\n",
        "            \"ampersand\"\n",
        "        ]\n",
        "\n",
        "path_train = 'hw5_code/dataset/spam/spam_data.mat'\n",
        "spam_data = scipy.io.loadmat(path_train)\n",
        "spam_training_data = spam_data[\"training_data\"]\n",
        "spam_training_labels = spam_data[\"training_labels\"]\n",
        "spam_test = spam_data[\"test_data\"]\n",
        "#here we want to randomize the data so we use the sk shuffling feature:\n",
        "spam_r = sk.utils.shuffle(spam_training_data, spam_training_labels, random_state=0)\n",
        "spl = round(.2 * spam_training_data.shape[0])\n",
        "spam_t_data = spam_r[0]\n",
        "spam_t_labels = spam_r[1]\n",
        "#we new re set up our data according to where our split for the 80 20 data was made:\n",
        "spam_training_data = spam_t_data[spl:]\n",
        "spam_training_labels = spam_t_labels[spl:]\n",
        "spam_validation_data = spam_t_data[:spl]\n",
        "spam_validation_labels = spam_t_labels[:spl]\n",
        "\n",
        "#here we define our class names for the spam and ham emails\n",
        "class_names = [\"Ham\",\"Spam\"]\n",
        "\n",
        "#we can now create our decision trees and our random forests for the spam data and get the \n",
        "#accuracies\n",
        "dt_s = DecisionTree(10, features)\n",
        "dt_s.fit(spam_training_data, spam_training_labels)\n",
        "dt_s_trainpred = dt_s.predict(spam_training_data)\n",
        "dt_s_valpred = dt_s.predict(spam_validation_data)\n",
        "rf_s = RandomForest(10, features, 5000, 5, 40)\n",
        "rf_s.fit(spam_training_data, spam_training_labels)\n",
        "rf_s_trainpred = rf_s.predict(spam_training_data)\n",
        "rf_s_valpred = rf_s.predict(spam_validation_data)\n",
        "print(\"Decision Tree Training Error: \", sklearn.metrics.accuracy_score(spam_training_labels, dt_s_trainpred))\n",
        "print(\"Decision Validation Error: \", sklearn.metrics.accuracy_score(spam_validation_labels, dt_s_valpred))\n",
        "print(\"Random Forest Training Error: \", sklearn.metrics.accuracy_score(spam_training_labels, rf_s_trainpred))\n",
        "print(\"Random Forest Validation Error: \", sklearn.metrics.accuracy_score(spam_validation_labels, rf_s_valpred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5BmI-guUWt",
        "outputId": "56290299-1a36-464f-ce5b-0481ac3eaf91"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:148: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:145: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:242: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  allpreds.append(stats.mode(curr_p[elt])[0][0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Error:  0.8619791666666666\n",
            "Decision Validation Error:  0.8191287878787878\n",
            "Random Forest Training Error:  0.8525094696969697\n",
            "Random Forest Validation Error:  0.8191287878787878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we want to visualize the nodes that we created\n",
        "#and determine if emails are spam or ham, and we want 2 cases, and we can choose\n",
        "#any portion of the training data to do this:\n",
        "\n",
        "dt_s.node_display(spam_training_data[9], class_names)\n",
        "print(\"\\n\")\n",
        "dt_s.node_display(spam_training_data[6], class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY36b_V8VjnZ",
        "outputId": "e19f37fb-3142-4dec-9d09-82bb985b79be"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('exclamation') < 1e-05\n",
            "('parenthesis') >= 1e-05\n",
            "('money') < 1e-05\n",
            "('pain') < 1e-05\n",
            "('featured') < 1e-05\n",
            "('energy') < 1e-05\n",
            "('meter') < 1e-05\n",
            "('dollar') < 1e-05\n",
            "('spam') < 1e-05\n",
            "('parenthesis') >= 1.00001\n",
            "Therefore this email was Ham.\n",
            "\n",
            "\n",
            "('exclamation') >= 1e-05\n",
            "('money') < 1e-05\n",
            "('parenthesis') >= 1e-05\n",
            "('dollar') < 1e-05\n",
            "('featured') < 1e-05\n",
            "('exclamation') < 9.222227777777777\n",
            "('spam') < 1e-05\n",
            "('drug') < 1e-05\n",
            "('energy') < 1e-05\n",
            "('meter') < 1e-05\n",
            "Therefore this email was Ham.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we want to make a plot of the validation accuracies for trees of differing\n",
        "#depths and we do so as dollows\n",
        "import matplotlib.pyplot as plt\n",
        "depth_vals = np.arange(1, 41)\n",
        "valacc = []\n",
        "for depth in depth_vals:\n",
        "  dt_s = DecisionTree(depth, features)\n",
        "  dt_s.fit(spam_training_data, spam_training_labels)\n",
        "  dtspred = dt_s.predict(spam_validation_data)\n",
        "  valacc.append(sklearn.metrics.accuracy_score(spam_validation_labels, dtspred))\n",
        "plt.plot(depth_vals, valacc)\n",
        "plt.xlabel(\"Decision Tree Depth\")\n",
        "plt.ylabel(\"Validation Set Accuracy\")\n",
        "plt.title(\"Tree Depth vs Validation Accuracy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gIkTkyoVVzI8",
        "outputId": "4ce94f04-79bf-450f-e616-d0c64c4e20d4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Tree Depth vs Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to set up the titanic data we just use what we had in the starter code:\n",
        "\n",
        "path_train = 'hw5_code/dataset/titanic/titanic_training.csv'\n",
        "data = genfromtxt(path_train, delimiter=',', dtype=None, encoding=None)\n",
        "path_test = 'hw5_code/dataset/titanic/titanic_test_data.csv'\n",
        "test_data = genfromtxt(path_test, delimiter=',', dtype=None, encoding=None)\n",
        "y = data[1:, -1]  # label = survived\n",
        "class_names = [\"Died\", \"Survived\"]\n",
        "labeled_idx = np.where(y != '')[0]\n",
        "y = np.array(y[labeled_idx])\n",
        "y = y.astype(float).astype(int)\n",
        "print(\"\\n\\nPart (b): preprocessing the titanic dataset\")\n",
        "X, onehot_features = preprocess(data[1:, :-1], onehot_cols=[1, 5, 7, 8])\n",
        "X = X[labeled_idx, :]\n",
        "Z, _ = preprocess(test_data[1:, :], onehot_cols=[1, 5, 7, 8])\n",
        "assert X.shape[1] == Z.shape[1]\n",
        "features = list(data[0, :-1]) + onehot_features\n",
        "\n",
        "\n",
        "#here we do the same thing we did with the spam data where we randomly shuffle\n",
        "#the data and we will then reassign the data accordingy:\n",
        "titanic_r = sk.utils.shuffle(X, y, random_state=0)\n",
        "spl=round(.2 * X.shape[0])\n",
        "titanic_t_data = titanic_r[0]\n",
        "titanic_t_labels = titanic_r[1]\n",
        "titanic_training_data = titanic_t_data[spl:]\n",
        "titanic_training_labels = titanic_t_labels[spl:]\n",
        "titanic_validation_data = titanic_t_data[:spl]\n",
        "titanic_validation_labels = titanic_t_labels[:spl]\n",
        "\n",
        "#here we set up the titanic decision tree and random forest then we get the errors\n",
        "#for it and we do so after we do everything we need to do for the spam data\n",
        "dt_t = DecisionTree(10, features)\n",
        "dt_t.fit(titanic_training_data, titanic_training_labels)\n",
        "dt_t_trainingpred = dt_t.predict(titanic_training_data)\n",
        "dt_t_validationpred = dt_t.predict(titanic_validation_data)\n",
        "rf_t = RandomForest(10, features, 2000, 3, 80)\n",
        "rf_t.fit(titanic_training_data, titanic_training_labels)\n",
        "rf_t_trainingpred = rf_t.predict(titanic_training_data)\n",
        "rf_t_validationpred = rf_t.predict(titanic_validation_data)\n",
        "\n",
        "print(\"Decision Tree Training Error: \", sklearn.metrics.accuracy_score(titanic_training_labels, dt_t_trainingpred))\n",
        "print(\"Decision Tree Validation Error: \", sklearn.metrics.accuracy_score(titanic_validation_labels, dt_t_validationpred))\n",
        "print(\"Random Forest Training Error: \", sklearn.metrics.accuracy_score(titanic_training_labels, rf_t_trainingpred))\n",
        "print(\"Random Forest Validation Error: \", sklearn.metrics.accuracy_score(titanic_validation_labels, rf_t_validationpred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r1OkyE7gQJL",
        "outputId": "852006bf-442f-4407-f7c6-5d92aaa04a9d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Part (b): preprocessing the titanic dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:283: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode = stats.mode(data[((data[:, i] < -1 - eps) +\n",
            "<ipython-input-62-a2668c47e886>:95: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:145: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:148: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n",
            "<ipython-input-62-a2668c47e886>:242: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  allpreds.append(stats.mode(curr_p[elt])[0][0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Training Error:  0.8973717146433041\n",
            "Decision Tree Validation Error:  0.735\n",
            "Random Forest Training Error:  0.8297872340425532\n",
            "Random Forest Validation Error:  0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we are told to do depth 3 decision trees\n",
        "dt_t_2 = DecisionTree(3, features)\n",
        "dt_t_2.fit(titanic_training_data, titanic_training_labels)\n",
        "\n",
        "class_names=[\"Died\",\"Survived\"]\n",
        "\n",
        "#here we create a new function in order to create\n",
        "#our shallow decision tree:\n",
        "def display_dt(node, d):\n",
        "  #the space here is to make sure that we can easily see the decision\n",
        "  #tree broken down\n",
        "  msg = \"            \" * d \n",
        "  #here we check if the node has a class yet, such as \n",
        "  #survived or died and if it is we stop, else we keep\n",
        "  #going\n",
        "  if not node.pred is None:\n",
        "    print(msg + class_names[node.pred])\n",
        "  else:\n",
        "    #here we will basically do one decision tree side all the way\n",
        "    #and then we move on to the next decision tree\n",
        "    msg += node.features[node.split_idx]\n",
        "    print(msg + \" < \" + str(node.thresh))\n",
        "    display_dt(node.left, d + 1)\n",
        "    print(msg + \" >= \" + str(node.thresh))\n",
        "    display_dt(node.right, d + 1)\n",
        "\n",
        "display_dt(dt_t_2, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3EFDDjFkC2t",
        "outputId": "7edf7941-d65b-475f-cab2-1ae3e294f97a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male < 1e-05\n",
            "            pclass < 2.11111\n",
            "                        S < 1e-05\n",
            "                                    Survived\n",
            "                        S >= 1e-05\n",
            "                                    Survived\n",
            "            pclass >= 2.11111\n",
            "                        S < 1e-05\n",
            "                                    Survived\n",
            "                        S >= 1e-05\n",
            "                                    Died\n",
            "male >= 1e-05\n",
            "            C < 1e-05\n",
            "                        pclass < 1.00001\n",
            "                                    Died\n",
            "                        pclass >= 1.00001\n",
            "                                    Died\n",
            "            C >= 1e-05\n",
            "                        age < -0.99999\n",
            "                                    Died\n",
            "                        age >= -0.99999\n",
            "                                    Died\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:98: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  self.pred = stats.mode(y).mode[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After doing all this we want to make our kaggle submission\n",
        "#and we define the results to csv function as we have done \n",
        "#before in previous assignments:\n",
        "import pandas as pd\n",
        "def results_to_csv(pred, name):\n",
        "  csvconv = pd.DataFrame({'Category': pred})\n",
        "  csvconv.index += 1\n",
        "  csvconv.to_csv(name, index_label='Id')\n",
        "\n",
        "results_to_csv(rf_s.predict(spam_test).astype(int),'testspam.csv')\n",
        "results_to_csv(rf_t.predict(Z).astype(int),'testtitanic.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "nVG5PhfqkMQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63245fc-e97f-48d3-a317-25d9fe6472f0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-a2668c47e886>:242: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  allpreds.append(stats.mode(curr_p[elt])[0][0])\n"
          ]
        }
      ]
    }
  ]
}