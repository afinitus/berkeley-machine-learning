{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbkVehhgBl0a",
        "outputId": "867b56d2-1b97-42fa-8b58-5552e21aaa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/gdrive/My Drive/hw1.zip\""
      ],
      "metadata": {
        "id": "SByJm1sQC1cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hw1/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtFjI-gbvS4M",
        "outputId": "eb1012ac-cec5-4991-f079-6a186eda57e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hw1/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, that in this code I used mnist and since I was copy pasting the data will say mnist_data or mnisttraininglabel etc., but in each case the np.load is loaded with the correct data, so it is NOT ALL MNIST, they are all loaded in with the correct data. ALSO I did not edit featurize.py."
      ],
      "metadata": {
        "id": "WcWQlpwP9qcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2 Code:**"
      ],
      "metadata": {
        "id": "K-jr1yJi_PUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def partition(data_one, data_two, amount):\n",
        "#we can make a general function that shuffles then partitions data \n",
        "#based on the amount to partition\n",
        "    if len(data_two) != len(data_one):\n",
        "        print(\"Labels and data don't match!\")\n",
        "        return 0\n",
        "    total = len(data_two)\n",
        "    #turn percent into a number\n",
        "    if amount < 0:\n",
        "        print(\"Amount Invalid!\")\n",
        "        return 0\n",
        "    if amount <= 1.0:\n",
        "        amount = int(amount * total)\n",
        "    trainingamt = total - amount\n",
        "    #want to shuffle data, so use rand perm fcn\n",
        "    rand = np.random.permutation(total)\n",
        "    traininglabel = data_two[rand][:trainingamt]\n",
        "    trainingdata = data_one[rand][:trainingamt]\n",
        "    validationlabel = data_two[rand][trainingamt:]\n",
        "    validationdata = data_one[rand][trainingamt:]\n",
        "    traininglabel = np.reshape(traininglabel, (len(traininglabel), -1))\n",
        "    trainingdata = np.reshape(trainingdata, (len(trainingdata), -1))\n",
        "    validationlabel = np.reshape(validationlabel, (len(validationlabel), -1))\n",
        "    validationdata = np.reshape(validationdata, (len(validationdata), -1))\n",
        "    return trainingdata, validationdata, traininglabel, validationlabel"
      ],
      "metadata": {
        "id": "y62L5bvlDwve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingpartition(data_one, data_two, amount):\n",
        "#we can make a general function that shuffles then partitions data \n",
        "#based on the amount to partition, but here the amount is the amount of training data\n",
        "    if len(data_two) != len(data_one):\n",
        "        print(\"Labels and data don't match!\")\n",
        "        return 0\n",
        "    #turn percent into a number\n",
        "    if amount < 0:\n",
        "        print(\"Amount Invalid!\")\n",
        "        return 0\n",
        "    if amount <= 1.0:\n",
        "        amount = int(amount * len(data_two))\n",
        "    trainingamt = len(data_two) - amount\n",
        "    #want to shuffle data, so use rand perm fcn\n",
        "    rand = np.random.permutation(len(data_two))\n",
        "    traininglabel = data_two[rand][trainingamt:]\n",
        "    trainingdata = data_one[rand][trainingamt:]\n",
        "    if amount == len(data_two):\n",
        "      validationlabel = data_two[rand][trainingamt:]\n",
        "      validationdata = data_one[rand][trainingamt:]\n",
        "    else:\n",
        "      validationlabel = data_two[rand][:trainingamt]\n",
        "      validationdata = data_one[rand][:trainingamt]\n",
        "    traininglabel = np.reshape(traininglabel, (len(traininglabel), -1))\n",
        "    trainingdata = np.reshape(trainingdata, (len(trainingdata), -1))\n",
        "    validationlabel = np.reshape(validationlabel, (len(validationlabel), -1))\n",
        "    validationdata = np.reshape(validationdata, (len(validationdata), -1))\n",
        "    return trainingdata, validationdata, traininglabel, validationlabel"
      ],
      "metadata": {
        "id": "RDnbaEmAMFE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3 Code:**"
      ],
      "metadata": {
        "id": "yEMxjlN-_Uz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "mnist_data = np.load(f\"mnist-data.npz\")\n",
        "mnisttraindata1, mnistvaldata, mnisttrainlabel1, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], 10000)\n",
        "vals = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
        "valaccuracies = []\n",
        "trainaccuracies = []\n",
        "for i in vals:\n",
        "  mnisttraindata, mnistvaldata1, mnisttrainlabel, mnistvallabel1 = trainingpartition(mnist_data['training_data'], mnist_data['training_labels'], i)\n",
        "  clf = svm.SVC(kernel=\"linear\")\n",
        "  clf.fit(mnisttraindata, mnisttrainlabel)\n",
        "  valpred = clf.predict(mnistvaldata)\n",
        "  valacc = sklearn.metrics.accuracy_score(mnistvallabel, valpred)\n",
        "  valaccuracies.append(valacc)\n",
        "  trainpred = clf.predict(mnisttraindata)\n",
        "  trainacc = sklearn.metrics.accuracy_score(mnisttrainlabel, trainpred)\n",
        "  trainaccuracies.append(trainacc)\n",
        "valaccuracies\n",
        "trainaccuracies\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"mnist\")\n",
        "plt.xlabel(\"number examples\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(vals, trainaccuracies, label=\"training\")\n",
        "plt.plot(vals, valaccuracies, label=\"validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TGRemQ7pWB6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "mnist_data = np.load(f\"spam-data.npz\")\n",
        "mnisttraindata1, mnistvaldata, mnisttrainlabel1, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], .2)\n",
        "\n",
        "vals = [100, 200, 500, 1000, 2000, len(mnist_data['training_data'])]\n",
        "valaccuracies = []\n",
        "trainaccuracies = []\n",
        "for i in vals:\n",
        "  mnisttraindata, mnistvaldata1, mnisttrainlabel, mnistvallabel1 = trainingpartition(mnist_data['training_data'], mnist_data['training_labels'], i)\n",
        "  clf = svm.SVC(kernel=\"linear\")\n",
        "  clf.fit(mnisttraindata, mnisttrainlabel)\n",
        "  valpred = clf.predict(mnistvaldata)\n",
        "  valacc = sklearn.metrics.accuracy_score(mnistvallabel, valpred)\n",
        "  valaccuracies.append(valacc)\n",
        "  trainpred = clf.predict(mnisttraindata)\n",
        "  trainacc = sklearn.metrics.accuracy_score(mnisttrainlabel, trainpred)\n",
        "  trainaccuracies.append(trainacc)\n",
        "valaccuracies\n",
        "trainaccuracies\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"spam\")\n",
        "plt.xlabel(\"number examples\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(vals, trainaccuracies, label=\"training\")\n",
        "plt.plot(vals, valaccuracies, label=\"validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BH_iWFS6_Uvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist_data = np.load(f\"cifar10-data.npz\")\n",
        "mnisttraindata1, mnistvaldata, mnisttrainlabel1, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], 5000)\n",
        "vals = [100, 200, 500, 1000, 2000, 5000]\n",
        "valaccuracies = []\n",
        "trainaccuracies = []\n",
        "for i in vals:\n",
        "  mnisttraindata, mnistvaldata1, mnisttrainlabel, mnistvallabel1 = trainingpartition(mnist_data['training_data'], mnist_data['training_labels'], i)\n",
        "  clf = svm.SVC(kernel=\"linear\")\n",
        "  clf.fit(mnisttraindata, mnisttrainlabel)\n",
        "  valpred = clf.predict(mnistvaldata)\n",
        "  valacc = sklearn.metrics.accuracy_score(mnistvallabel, valpred)\n",
        "  valaccuracies.append(valacc)\n",
        "  trainpred = clf.predict(mnisttraindata)\n",
        "  trainacc = sklearn.metrics.accuracy_score(mnisttrainlabel, trainpred)\n",
        "  trainaccuracies.append(trainacc)\n",
        "valaccuracies\n",
        "trainaccuracies\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"cifar10\")\n",
        "plt.xlabel(\"number examples\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(vals, trainaccuracies, label=\"training\")\n",
        "plt.plot(vals, valaccuracies, label=\"validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C_lG2okiBrPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4 Code:**"
      ],
      "metadata": {
        "id": "vnqI2MlF_YvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn\n",
        "#created tool for training the model based on the C value we are using\n",
        "def hyperparam_train(tdata_one,tdata_two, C):\n",
        "    new = svm.SVC(kernel=\"linear\", C=C)\n",
        "    new.fit(tdata_one,tdata_two)\n",
        "    return new\n",
        "\n",
        "def hyperparam_fit(tdata_one, tdata_two, vdata_one, vdata_two, Cvals):\n",
        "    # we need something to hold our fits for different c values which we will return\n",
        "    fits = []\n",
        "    #here we want to iterate over the c values and try them out\n",
        "    #we want to create a sample model and test that against the validation data\n",
        "    #using this accuracy we will find the best c values\n",
        "    for c in Cvals:\n",
        "      # i later on added this amount parameter so that i can edit the amount of training data we use\n",
        "        test = hyperparam_train(tdata_one,tdata_two,c)\n",
        "        pred = test.predict(vdata_one)\n",
        "        acc = sklearn.metrics.accuracy_score(vdata_two, pred)\n",
        "        fits.append([c, acc])\n",
        "    return fits"
      ],
      "metadata": {
        "id": "YESsU-HIU1pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = np.load(f\"mnist-data.npz\")\n",
        "mnisttraindata1, mnistvaldata, mnisttrainlabel1, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], 10000)\n",
        "mnisttraindata, mnistvaldata1, mnisttrainlabel, mnistvallabel1 = trainingpartition(mnist_data['training_data'], mnist_data['training_labels'], 10000)\n",
        "print(hyperparam_fit(mnisttraindata, mnisttrainlabel, mnistvaldata, mnistvallabel, [.01, .03, .05, .07, .15, .27, .54, .8, 1, 5]))"
      ],
      "metadata": {
        "id": "xxZdTDtfxsUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5 Code:**"
      ],
      "metadata": {
        "id": "gm_jB5jM_j2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import sklearn\n",
        "\n",
        "#I have set up a new train for the kfold but it is identical to the previous ones\n",
        "#i added this here for simplicity when running this code block\n",
        "def kfold_train(tdata_one,tdata_two, C, KERNEL):\n",
        "    new = svm.SVC(kernel=KERNEL, C=C)\n",
        "    new.fit(tdata_one,tdata_two)\n",
        "    return new\n",
        "\n",
        "def k_fit(tdata_one, tdata_two, k, Cvals, kernel):\n",
        "  #this will gold all of our fits in the end for the c vals\n",
        "    fits = []\n",
        "    #we make these to hold our k many data sets\n",
        "    kdata_one = k * [0]\n",
        "    kdata_two = k * [0]\n",
        "    #we are now going to be splitting the data, but because it wont be perfect all the time\n",
        "    #we need to split so the last one will go all the way to the end of our data\n",
        "    rand = np.random.permutation(len(tdata_one))\n",
        "    splits = len(tdata_one) // k\n",
        "    if len(tdata_one) != len(tdata_two):\n",
        "        print(\"Labels and data don't match!\")\n",
        "        return 0\n",
        "        #we are making k splits in the data for our cross validation\n",
        "    for i in range(k):\n",
        "        start = i * splits\n",
        "        if i != k-1:\n",
        "            end = splits * (i + 1)\n",
        "        else:\n",
        "            end = len(tdata_one)\n",
        "        #these are the corresponding data splits\n",
        "        kdata_one[i] = tdata_one[rand][start:end]\n",
        "        kdata_two[i] = tdata_two[rand][start:end]\n",
        "    for c in Cvals:\n",
        "        k_acc = []\n",
        "        for i in range(k):\n",
        "          #here we iterate through all the k many splits and make predictions then we average these to get\n",
        "          #the overall accuracy\n",
        "          #we combine all other data but the ith set which is our validation set:\n",
        "            newdataone = np.concatenate(kdata_one[:i] + kdata_one[i+1:], axis = 0)\n",
        "            newdatatwo = np.concatenate(kdata_two[:i] + kdata_two[i+1:], axis = 0)\n",
        "            test = kfold_train(newdataone, newdatatwo, c, kernel)\n",
        "            pred = test.predict(kdata_one[i])\n",
        "            acc = sklearn.metrics.accuracy_score(kdata_two[i], pred)\n",
        "            k_acc.append(acc)\n",
        "        fits.append([c, np.mean(k_acc)])\n",
        "    return fits"
      ],
      "metadata": {
        "id": "5IN-7JPoMt0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = np.load(f\"spam-data.npz\")\n",
        "mnisttraindata, mnistvaldata, mnisttrainlabel, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], 0.2)\n",
        "print(k_fit(mnisttraindata, mnisttrainlabel, 5, [0.2, 0.4, 0.8, 1.6, 3, 10, 20, 45], \"rbf\"))"
      ],
      "metadata": {
        "id": "VC1mcrIDNJgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6 Code:**"
      ],
      "metadata": {
        "id": "YSDBPMfu_0hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn import svm\n",
        "import sklearn\n",
        "\n",
        "#again this is going to be the same training function as we have used twice before but\n",
        "#again this is here for simplicity of running this code block\n",
        "def kaggle_train(tdata_one,tdata_two, C, Kernel):\n",
        "    new = svm.SVC(kernel=Kernel, C=C)\n",
        "    new.fit(tdata_one,tdata_two)\n",
        "    return new\n",
        "\n",
        "def submit_kaggle(tdata_one, tdata_two, filename, vdata, C, kernel):\n",
        "  #here we just make our test model with our specified C value and then we predict\n",
        "  #I print the predictions for my own sake of revising errors\n",
        "    test = kaggle_train(tdata_one, tdata_two, C, kernel)\n",
        "    pred = test.predict(vdata)\n",
        "    print(pred)\n",
        "    #saving the csv in the correct format\n",
        "    csv = os.path.join(os.getcwd(), '%s_soln.csv' % filename)\n",
        "    f = open(csv, 'w')\n",
        "    f.write(\"Id,Category\\n\")\n",
        "    i = 1\n",
        "    for val in pred:\n",
        "        f.write(str(i) + ',' + str(val) + '\\n')\n",
        "        i += 1\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "7_gHFDh1iidj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mnist_data = np.load(f\"spam-data.npz\")\n",
        "mnisttraindata, mnistvaldata, mnisttrainlabel, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], .2)\n",
        "testdata = np.reshape(mnist_data['test_data'], (len(mnist_data['test_data']), -1))\n",
        "submit_kaggle(mnisttraindata, mnisttrainlabel, \"TESTspam\", testdata, 45, \"rbf\")"
      ],
      "metadata": {
        "id": "FjcIDZ_jizMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mnist_data = np.load(f\"mnist-data.npz\")\n",
        "mnisttraindata, mnistvaldata, mnisttrainlabel, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], .2)\n",
        "testdata = np.reshape(mnist_data['test_data'], (len(mnist_data['test_data']), -1))\n",
        "submit_kaggle(mnisttraindata, mnisttrainlabel, \"TESTmnist\", testdata, 1, \"linear\")"
      ],
      "metadata": {
        "id": "5l1eLKC7T7j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mnist_data = np.load(f\"cifar10-data.npz\")\n",
        "mnisttraindata, mnistvaldata, mnisttrainlabel, mnistvallabel = partition(mnist_data['training_data'], mnist_data['training_labels'], .2)\n",
        "testdata = np.reshape(mnist_data['test_data'], (len(mnist_data['test_data']), -1))\n",
        "submit_kaggle(mnisttraindata, mnisttrainlabel, \"TESTcifar\", testdata, 1, \"linear\")"
      ],
      "metadata": {
        "id": "s7deAne2UB4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}